{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sam99dave/100days/blob/master/SIH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL_I3SAEpCRs",
        "colab_type": "code",
        "outputId": "3c085f2f-bd13-412e-ae3f-609fb27b7b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cDzQKFsMKeP",
        "colab_type": "code",
        "outputId": "db9fa234-3344-48db-afbf-839f1acbbd43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "!git clone https://github.com/sentinel-hub/eo-learn.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'eo-learn'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 8451 (delta 40), reused 57 (delta 21), pack-reused 8343\u001b[K\n",
            "Receiving objects: 100% (8451/8451), 295.44 MiB | 14.43 MiB/s, done.\n",
            "Resolving deltas: 100% (5106/5106), done.\n",
            "Checking out files: 100% (336/336), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-SSBFB7rKYc",
        "colab_type": "code",
        "outputId": "05102f32-2ef7-40e0-e317-3046e20adb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install eo-learn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eo-learn\n",
            "  Downloading https://files.pythonhosted.org/packages/45/40/a2d54e2337e6fe4cef3e3b4e2610db926fbed6e5d0d1d3d8208a01a936d8/eo-learn-0.7.0.tar.gz\n",
            "Collecting eo-learn-core>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/75/b5/0bcbccb799d6b1de680e8c9c14932da3db1fb8f0b1de2400a85f0355af15/eo-learn-core-0.7.0.tar.gz\n",
            "Collecting eo-learn-coregistration>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/c4/0fbbc1f0906d81764f8fd41a9528f96b7687863b70cb8983c802f0909dad/eo-learn-coregistration-0.7.0.tar.gz\n",
            "Collecting eo-learn-features>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/3b/0ff0c8ae0ad1aae9081cfc3b93f13ae20a56e5913abd657de7b7bc196fcf/eo-learn-features-0.7.0.tar.gz\n",
            "Collecting eo-learn-geometry>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/b7/7535c91e0da5c3756c779e6dbcc3ef7bf1847440c39c390c3aaa961be226/eo-learn-geometry-0.7.0.tar.gz\n",
            "Collecting eo-learn-io>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/20/9de50514d0c95dddb7ab6fc4d23d230cc8a6c037d501cf647778d9113bb6/eo-learn-io-0.7.0.tar.gz\n",
            "Collecting eo-learn-mask>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/cb/c415fa10cc73311459b38bb1d1a2b0c860beca2e9f847b3914197e29588a/eo-learn-mask-0.7.0.tar.gz (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 5.7MB/s \n",
            "\u001b[?25hCollecting eo-learn-ml-tools>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/27/e3/cce5081124744c2e61109b75cda2a6ae548d5c6f3a6e3f17a086b1612f27/eo-learn-ml-tools-0.7.0.tar.gz\n",
            "Collecting eo-learn-visualization>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/9f/4718173039a5da3eb1c399f8fe62775f5f9639b7aa97cbbbdd068dc39e86/eo-learn-visualization-0.7.0.tar.gz\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.6/dist-packages (from eo-learn-core>=0.7.0->eo-learn) (19.3.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from eo-learn-core>=0.7.0->eo-learn) (1.10.47)\n",
            "Collecting fs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/b6/9a5d4edd6e933bebfd15c64525ea8c787fc62fcbb0d167040771600f77eb/fs-2.4.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 44.3MB/s \n",
            "\u001b[?25hCollecting fs-s3fs\n",
            "  Downloading https://files.pythonhosted.org/packages/14/71/9b36a6dbd28386e2028e4ab9aac9c30874fc9c74d6b8fa0c8c2806548311/fs_s3fs-1.1.1-py2.py3-none-any.whl\n",
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/0c/e6c99e561b03482220f00443f610ccf4dce9b50f4b1093d735f93c6fc8c6/geopandas-0.6.2-py2.py3-none-any.whl (919kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from eo-learn-core>=0.7.0->eo-learn) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from eo-learn-core>=0.7.0->eo-learn) (2.6.1)\n",
            "Collecting sentinelhub==3.0.0b1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/96/e3be95950b755c18a101f88c0ddb3221166194ddb250209c4f13c3775db8/sentinelhub-3.0.0b1.tar.gz (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from eo-learn-core>=0.7.0->eo-learn) (4.28.1)\n",
            "Collecting opencv-contrib-python-headless>=4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/a1/13ed30f2e50dfee701fda7f20972885ea3f8b38609846da06bf7dfd7efdf/opencv_contrib_python_headless-4.1.2.30-cp36-cp36m-manylinux1_x86_64.whl (27.8MB)\n",
            "\u001b[K     |████████████████████████████████| 27.8MB 110kB/s \n",
            "\u001b[?25hCollecting thunder-registration\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f3/0fcb78e36f6c303135cd56d28ffd8be98bbc34075dee9a4c09a86aa48404/thunder-registration-1.0.1.tar.gz\n",
            "Requirement already satisfied: numba>=0.43.1 in /usr/local/lib/python3.6/dist-packages (from eo-learn-features>=0.7.0->eo-learn) (0.47.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from eo-learn-features>=0.7.0->eo-learn) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from eo-learn-features>=0.7.0->eo-learn) (0.22.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eo-learn-features>=0.7.0->eo-learn) (1.4.1)\n",
            "Requirement already satisfied: descartes in /usr/local/lib/python3.6/dist-packages (from eo-learn-geometry>=0.7.0->eo-learn) (1.1.0)\n",
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/e5/7052a3eef72af7e883a280d8dff64f4ea44cb92ec25ffb1d00ce27bc1a12/rasterio-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (18.0MB)\n",
            "\u001b[K     |████████████████████████████████| 18.0MB 195kB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from eo-learn-geometry>=0.7.0->eo-learn) (1.6.4.post2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from eo-learn-mask>=0.7.0->eo-learn) (0.14.1)\n",
            "Collecting s2cloudless>=1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/5e/85b0e3fc311a12d28c978a0536d33d15337a37789965645d28088ba94d4b/s2cloudless-1.4.0.tar.gz (4.8MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8MB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from eo-learn-ml-tools>=0.7.0->eo-learn) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from eo-learn-ml-tools>=0.7.0->eo-learn) (0.25.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from eo-learn-ml-tools>=0.7.0->eo-learn) (0.9.0)\n",
            "Requirement already satisfied: graphviz>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from eo-learn-visualization>=0.7.0->eo-learn) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eo-learn-visualization>=0.7.0->eo-learn) (2.10.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from eo-learn-visualization>=0.7.0->eo-learn) (1.3.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from eo-learn-visualization>=0.7.0->eo-learn) (2.1.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->eo-learn-core>=0.7.0->eo-learn) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->eo-learn-core>=0.7.0->eo-learn) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->eo-learn-core>=0.7.0->eo-learn) (0.9.4)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from fs->eo-learn-core>=0.7.0->eo-learn) (1.12.0)\n",
            "Collecting appdirs~=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fs->eo-learn-core>=0.7.0->eo-learn) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from fs->eo-learn-core>=0.7.0->eo-learn) (42.0.2)\n",
            "Collecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/f7/9899f8a9a2e38601472fe1079ce5088f58833221c8b8507d8b5eafd5404a/Fiona-1.8.13-cp36-cp36m-manylinux1_x86_64.whl (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 32.3MB/s \n",
            "\u001b[?25hCollecting pyproj\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/70/eedc98cd52b86de24a1589c762612a98bea26cde649ffdd60c1db396cce8/pyproj-2.4.2.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 17.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (0.33.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (2.21.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (7.0)\n",
            "Collecting tifffile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/7e/5fab62e8247609af666908b8253d911cf315b1078d5d0135443d43719e6b/tifffile-2019.7.26.2-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (6.2.2)\n",
            "Collecting utm\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/77/180f06153f2c1a8caf8409ff6365abc9423ec4ebc3991dfe4a3228bc09d4/utm-0.5.0.tar.gz\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.6/dist-packages (from sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (3.1.0)\n",
            "Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.6/dist-packages (from sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (1.3.0)\n",
            "Collecting aenum>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/5f/320aa3eb68773a147f9a804167087160ca230f530b03eee30ec33f0070c7/aenum-2.2.3-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 5.0MB/s \n",
            "\u001b[?25hCollecting thunder-python>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/5a/2b2693188e6a287961249b045a5f1425d5d7c5aba817087b7a55441abbb2/thunder-python-1.4.2.tar.gz (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.1->eo-learn-features>=0.7.0->eo-learn) (0.31.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->eo-learn-features>=0.7.0->eo-learn) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->eo-learn-features>=0.7.0->eo-learn) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->eo-learn-features>=0.7.0->eo-learn) (2.4)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Collecting click-plugins\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lightgbm>=2.0.11 in /usr/local/lib/python3.6/dist-packages (from s2cloudless>=1.3.0->eo-learn-mask>=0.7.0->eo-learn) (2.2.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->eo-learn-ml-tools>=0.7.0->eo-learn) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->eo-learn-ml-tools>=0.7.0->eo-learn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->eo-learn-ml-tools>=0.7.0->eo-learn) (2.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eo-learn-visualization>=0.7.0->eo-learn) (1.1.1)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->eo-learn-core>=0.7.0->eo-learn) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->eo-learn-core>=0.7.0->eo-learn) (0.15.2)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelhub==3.0.0b1->eo-learn-core>=0.7.0->eo-learn) (3.0.4)\n",
            "Collecting imagecodecs-lite>=2019.12.2; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/52/d96e09e659b8b72bacfa108b135ba64c4156bc9497d7b4643b4c9610a8b2/imagecodecs_lite-2019.12.3-cp36-cp36m-manylinux2010_x86_64.whl (706kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto>=2.36.0 in /usr/local/lib/python3.6/dist-packages (from thunder-python>=1.2.0->thunder-registration->eo-learn-coregistration>=0.7.0->eo-learn) (2.49.0)\n",
            "Collecting bolt-python>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/26/97cf2e6b52c4b2458d3fc9f3e50048e7a066c95e173716a4d39bf15a7189/bolt-python-0.7.1.tar.gz\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->eo-learn-features>=0.7.0->eo-learn) (4.4.1)\n",
            "Building wheels for collected packages: eo-learn, eo-learn-core, eo-learn-coregistration, eo-learn-features, eo-learn-geometry, eo-learn-io, eo-learn-mask, eo-learn-ml-tools, eo-learn-visualization, sentinelhub, thunder-registration, s2cloudless, utm, thunder-python, bolt-python\n",
            "  Building wheel for eo-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn: filename=eo_learn-0.7.0-cp36-none-any.whl size=5756 sha256=75bf168ecb3b54c1f425b449e46efe4acb0aa3253913abccdd0da9dd9af65982\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/61/02/43ebe5d19bcc324dd67ed8956c50519e3f1a93369467358b67\n",
            "  Building wheel for eo-learn-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-core: filename=eo_learn_core-0.7.0-cp36-none-any.whl size=42438 sha256=5577afdbcc54b9fb903682d2f0be9e21af8ba7e8acbdd2bc2f04f321961efff6\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/4e/b7/c6d7cb9c39a5a9cda6005efff21ee84ed7d77cac429d9b6a37\n",
            "  Building wheel for eo-learn-coregistration (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-coregistration: filename=eo_learn_coregistration-0.7.0-cp36-none-any.whl size=10946 sha256=10d373bc77514330b9d48f30dcc5da20aa11700ffe18e745b3584aa6d6f87d34\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/7a/0f/0b3d151d68142b3c94c41153e4183d9b6c76db1710655647bb\n",
            "  Building wheel for eo-learn-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-features: filename=eo_learn_features-0.7.0-cp36-none-any.whl size=32102 sha256=38e9c037adfb03379bf22b62a66c8f5a927c48ca98147cd96108d1f92a977d0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/e4/dd/8fc602a9af905ef50d2dbf240891944111a613de4bc62b7569\n",
            "  Building wheel for eo-learn-geometry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-geometry: filename=eo_learn_geometry-0.7.0-cp36-none-any.whl size=17458 sha256=74f98970e2ead7d3ff90e4486bb243e69b7bff9a9e1fae50c4503cec264084f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/dc/64/bb549e3a0aa64026b046b13422db42e5c4b705e7e3aefce2e0\n",
            "  Building wheel for eo-learn-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-io: filename=eo_learn_io-0.7.0-cp36-none-any.whl size=19566 sha256=beb8154781a95f9aa8ccac34aa6f5767e7396607f44c57fcd07ac9ec2391ad21\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/dc/9c/d99d49033189af64e74875328b2b138fc61b1e7b650dd8d82f\n",
            "  Building wheel for eo-learn-mask (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-mask: filename=eo_learn_mask-0.7.0-cp36-none-any.whl size=10495215 sha256=56686efa4ea6dc161e0818f28a08d4e485cdc49883777395355f915ccb94f760\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/99/4b/a43426e7ce90e9c94c609433ff83f5c4d5e1d7a669664af7e3\n",
            "  Building wheel for eo-learn-ml-tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-ml-tools: filename=eo_learn_ml_tools-0.7.0-cp36-none-any.whl size=18214 sha256=721094d83e31dc1ac1b3fdd833ce73a4c19581e148e67b5bf30a3ade6cfeff53\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1c/76/0bd2bcbb09c6eac1cf35307f4fa5f7866f14e6298c954925db\n",
            "  Building wheel for eo-learn-visualization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eo-learn-visualization: filename=eo_learn_visualization-0.7.0-cp36-none-any.whl size=14697 sha256=6328b1a7dc471d8717e2e4357061e2b3389f5f408394469a2c5008ac93cac66e\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/c9/2f/a064c31fe7e6da178c7ac3de0e7501dc57e586245f818f092d\n",
            "  Building wheel for sentinelhub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentinelhub: filename=sentinelhub-3.0.0b1-cp36-none-any.whl size=187944 sha256=4bb4e1ae6615e07b2a549e4c82490047fce775398e8a7d297e51aebc8f8c8d91\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f7/35/5ddccebb42b7e49da792bf9fb818e38747450e26bfd1b4822f\n",
            "  Building wheel for thunder-registration (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thunder-registration: filename=thunder_registration-1.0.1-py2.py3-none-any.whl size=5342 sha256=981bf844a9967b5f1c2f983e1d1fe70f52d6cae44c268f5286f9f1ded2348f78\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/d2/bb/c75a11e0587a251c0f601b0d51c66f8be485204ee49ef5c73f\n",
            "  Building wheel for s2cloudless (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for s2cloudless: filename=s2cloudless-1.4.0-cp36-none-any.whl size=4763250 sha256=c907e1e300db61eed1bb85118fa21ccf3034ed77430b48aa449523fc574360d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/28/c8/6663561e912e382b775b70d3b619107a71d638b0a83f785a28\n",
            "  Building wheel for utm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utm: filename=utm-0.5.0-cp36-none-any.whl size=5903 sha256=d1cc2cac2adecf134cfa126e4889e1b2dd1d92c7086f1d9d7635545c00284f36\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/85/c2/314ffed39b8e02ca623e9b7d2ad7fcf3f8544a0e77c096be76\n",
            "  Building wheel for thunder-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thunder-python: filename=thunder_python-1.4.2-cp36-none-any.whl size=43292 sha256=5b5fa10a772cb3c1b3fa4f9f064b36d345fcee3c2cebbe1aa51d199b7fb48868\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/5c/dc/26bd848c4dc9a47927f65bd6773cd4d1527c8bf1a2b23f83dd\n",
            "  Building wheel for bolt-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bolt-python: filename=bolt_python-0.7.1-cp36-none-any.whl size=31180 sha256=c4c7807e3d644eb2a7b5af4e086bddb050c5b941a75031e20045b5c80a20220e\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/dc/37/3dee4520b844d67fb7e179616ea8c909f05160fafb938be942\n",
            "Successfully built eo-learn eo-learn-core eo-learn-coregistration eo-learn-features eo-learn-geometry eo-learn-io eo-learn-mask eo-learn-ml-tools eo-learn-visualization sentinelhub thunder-registration s2cloudless utm thunder-python bolt-python\n",
            "Installing collected packages: appdirs, fs, fs-s3fs, cligj, munch, click-plugins, fiona, pyproj, geopandas, imagecodecs-lite, tifffile, utm, aenum, sentinelhub, eo-learn-core, opencv-contrib-python-headless, bolt-python, thunder-python, thunder-registration, eo-learn-coregistration, eo-learn-features, snuggs, affine, rasterio, eo-learn-geometry, eo-learn-io, s2cloudless, eo-learn-mask, eo-learn-ml-tools, eo-learn-visualization, eo-learn\n",
            "Successfully installed aenum-2.2.3 affine-2.3.0 appdirs-1.4.3 bolt-python-0.7.1 click-plugins-1.1.1 cligj-0.5.0 eo-learn-0.7.0 eo-learn-core-0.7.0 eo-learn-coregistration-0.7.0 eo-learn-features-0.7.0 eo-learn-geometry-0.7.0 eo-learn-io-0.7.0 eo-learn-mask-0.7.0 eo-learn-ml-tools-0.7.0 eo-learn-visualization-0.7.0 fiona-1.8.13 fs-2.4.11 fs-s3fs-1.1.1 geopandas-0.6.2 imagecodecs-lite-2019.12.3 munch-2.5.0 opencv-contrib-python-headless-4.1.2.30 pyproj-2.4.2.post1 rasterio-1.1.2 s2cloudless-1.4.0 sentinelhub-3.0.0b1 snuggs-1.4.7 thunder-python-1.4.2 thunder-registration-1.0.1 tifffile-2019.7.26.2 utm-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiLpTiQfpqbV",
        "colab_type": "code",
        "outputId": "0f535fef-977a-4ce2-b9c9-a582660055df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "!git clone https://github.com/sentinel-hub/sentinelhub-py.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentinelhub-py'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 2875 (delta 117), reused 114 (delta 48), pack-reused 2668\u001b[K\n",
            "Receiving objects: 100% (2875/2875), 62.15 MiB | 12.29 MiB/s, done.\n",
            "Resolving deltas: 100% (2001/2001), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbYyki82pz8f",
        "colab_type": "code",
        "outputId": "d182b17d-ee48-4052-c15e-578029c895a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%cd sentinelhub-py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sentinelhub-py/sentinelhub-py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGjZqQl9ox8q",
        "colab_type": "code",
        "outputId": "45377dfa-3a4d-41e4-d415-b27fba4736b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "pip install sentinelhub --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: sentinelhub in /usr/local/lib/python3.6/dist-packages (3.0.0b1)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (6.2.2)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (1.10.47)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: aenum>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (2.2.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: tifffile in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (2019.7.26.2)\n",
            "Requirement already satisfied, skipping upgrade: utm in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pyproj in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (2.4.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: shapely in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (1.6.4.post2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: botocore in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (1.13.47)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=18.2.0 in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib in /usr/local/lib/python3.6/dist-packages (from sentinelhub) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->sentinelhub) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->sentinelhub) (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->sentinelhub) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: imagecodecs-lite>=2019.12.2; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from tifffile->sentinelhub) (2019.12.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore->sentinelhub) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore->sentinelhub) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelhub) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelhub) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->sentinelhub) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6BLfcyto8uY",
        "colab_type": "code",
        "outputId": "7389da20-88a2-45f2-90bb-3894d3ee08b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "!sentinelhub.config --show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "{\n",
            "  \"instance_id\": \"\",\n",
            "  \"sh_client_id\": \"\",\n",
            "  \"sh_client_secret\": \"\",\n",
            "  \"sh_base_url\": \"https://services.sentinel-hub.com\",\n",
            "  \"geopedia_wms_url\": \"http://service.geopedia.world\",\n",
            "  \"geopedia_rest_url\": \"https://www.geopedia.world/rest\",\n",
            "  \"aws_access_key_id\": \"\",\n",
            "  \"aws_secret_access_key\": \"\",\n",
            "  \"aws_metadata_url\": \"https://roda.sentinel-hub.com\",\n",
            "  \"aws_s3_l1c_bucket\": \"sentinel-s2-l1c\",\n",
            "  \"aws_s3_l2a_bucket\": \"sentinel-s2-l2a\",\n",
            "  \"opensearch_url\": \"http://opensearch.sentinel-hub.com/resto/api/collections/Sentinel2\",\n",
            "  \"max_wfs_records_per_query\": 100,\n",
            "  \"max_opensearch_records_per_query\": 500,\n",
            "  \"max_download_attempts\": 4,\n",
            "  \"download_sleep_time\": 5,\n",
            "  \"download_timeout_seconds\": 120\n",
            "}\n",
            "Configuration file location: /usr/local/lib/python3.6/dist-packages/sentinelhub/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TkyDat5qNLK",
        "colab_type": "code",
        "outputId": "2f521da4-e5b3-4d7b-d8b4-1eb2cc9311a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!sentinelhub.config --instance_id \"e52da223-f972-43e9-9adc-660887c6a231\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "The value of parameter 'instance_id' was updated to 'e52da223-f972-43e9-9adc-660887c6a231'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-XclotnqNSp",
        "colab_type": "code",
        "outputId": "ad128af4-0faa-4fbd-d6d4-5033874454b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "!sentinelhub.config --show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "{\n",
            "  \"instance_id\": \"e52da223-f972-43e9-9adc-660887c6a231\",\n",
            "  \"sh_client_id\": \"\",\n",
            "  \"sh_client_secret\": \"\",\n",
            "  \"sh_base_url\": \"https://services.sentinel-hub.com\",\n",
            "  \"geopedia_wms_url\": \"http://service.geopedia.world\",\n",
            "  \"geopedia_rest_url\": \"https://www.geopedia.world/rest\",\n",
            "  \"aws_access_key_id\": \"\",\n",
            "  \"aws_secret_access_key\": \"\",\n",
            "  \"aws_metadata_url\": \"https://roda.sentinel-hub.com\",\n",
            "  \"aws_s3_l1c_bucket\": \"sentinel-s2-l1c\",\n",
            "  \"aws_s3_l2a_bucket\": \"sentinel-s2-l2a\",\n",
            "  \"opensearch_url\": \"http://opensearch.sentinel-hub.com/resto/api/collections/Sentinel2\",\n",
            "  \"max_wfs_records_per_query\": 100,\n",
            "  \"max_opensearch_records_per_query\": 500,\n",
            "  \"max_download_attempts\": 4,\n",
            "  \"download_sleep_time\": 5,\n",
            "  \"download_timeout_seconds\": 120\n",
            "}\n",
            "Configuration file location: /usr/local/lib/python3.6/dist-packages/sentinelhub/config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8SxQfnoqsTa",
        "colab_type": "code",
        "outputId": "d8810b05-1931-4dac-a144-b8d864b2d60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "!pip install geopandas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.13)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (0.25.3)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.4.2.post1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.6.4.post2)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.12.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOI1PXsxr4g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dont run these commands as they change the sentinelhub version\n",
        "##!python setup.py build\n",
        "#!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQwipZB2krfw",
        "colab_type": "code",
        "outputId": "aa4ac0fc-70fb-4581-fc48-a70589e472f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        }
      },
      "source": [
        "# Firstly, some necessary imports\n",
        "\n",
        "# Jupyter notebook related\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "# Built-in modules\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "import datetime\n",
        "import itertools\n",
        "from enum import Enum\n",
        "\n",
        "# Basics of Python data handling and visualization\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from shapely.geometry import Polygon\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "# Machine learning \n",
        "import lightgbm as lgb\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Imports from eo-learn and sentinelhub-py\n",
        "from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n",
        "    LoadFromDisk, SaveToDisk, EOExecutor\n",
        "from eolearn.io import S2L1CWCSInput\n",
        "from eolearn.io import ExportToTiff\n",
        "from eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask\n",
        "from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\n",
        "from eolearn.features import LinearInterpolation, SimpleFilterTask\n",
        "from sentinelhub import BBoxSplitter, BBox, CRS, CustomUrlParam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8e4b07010cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Imports from eo-learn and sentinelhub-py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEOTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOPatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearWorkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOverwritePermission\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mLoadFromDisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveToDisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS2L1CWCSInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportToTiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meolearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddCloudMaskTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_s2_pixel_cloud_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAddValidDataMaskTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/eolearn/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeopedia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddGeopediaFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlocal_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportToTiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportFromTiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentinelHubInputTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentinelHubDemTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0.7.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/eolearn/io/processing_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentinelhub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebFeatureService\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMimeType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentinelHubDownloadClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownloadRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSHConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mbbox_to_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_time_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentinelhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinelhub_request\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mshr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'SentinelHubDownloadClient'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEl61R3lMgmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd sentinelhub-py/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khcaHmUBLcNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Folder where data for running the notebook is stored\n",
        "DATA_FOLDER = os.path.join('..','eo-learn', 'example_data')\n",
        "\n",
        "\n",
        "# Load geojson file\n",
        "country = gpd.read_file(os.path.join(DATA_FOLDER, 'eastern_france.geojson'))\n",
        "\n",
        "# Convert CRS to UTM_33N\n",
        "country_crs = CRS.UTM_33N\n",
        "country = country.to_crs(crs={'init': CRS.ogc_string(country_crs)})\n",
        "\n",
        "# Get the country's shape in polygon format\n",
        "country_shape = country.geometry.values[-1]\n",
        "\n",
        "# Plot country\n",
        "country.plot()\n",
        "plt.axis('off');\n",
        "\n",
        "# Print size \n",
        "print('Dimension of the area is {0:.0f} x {1:.0f} m2'.format(country_shape.bounds[2] - country_shape.bounds[0],\n",
        "                                                             country_shape.bounds[3] - country_shape.bounds[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RfcGzw3LcLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_smaller_patches = True\n",
        "\n",
        "# Create the splitter to obtain a list of bboxes\n",
        "bbox_splitter_large = BBoxSplitter([country_shape], country_crs, (25, 17))\n",
        "bbox_splitter_small = BBoxSplitter([country_shape], country_crs, (25 * 3, 17 * 3))\n",
        "\n",
        "bbox_splitter = bbox_splitter_small if use_smaller_patches else bbox_splitter_large\n",
        "\n",
        "bbox_list = np.array(bbox_splitter.get_bbox_list())\n",
        "info_list = np.array(bbox_splitter.get_info_list())\n",
        "\n",
        "# For the future examples, we will be using a specific set of patches,\n",
        "# but you are free to change the patch ID numbers in the scope of this example\n",
        "# Select a central patch\n",
        "ID = 1549 if use_smaller_patches else 190 \n",
        "\n",
        "# Obtain surrounding patches\n",
        "patchIDs = []\n",
        "for idx, [bbox, info] in enumerate(zip(bbox_list, info_list)):\n",
        "    if (abs(info['index_x'] - info_list[ID]['index_x']) <= 1 and\n",
        "        abs(info['index_y'] - info_list[ID]['index_y']) <= 1):\n",
        "        patchIDs.append(idx)\n",
        "\n",
        "# Check if final size is 3x3\n",
        "if len(patchIDs) != 9:\n",
        "    print('Warning! Use a different central patch ID, this one is on the border.')\n",
        "    \n",
        "# Change the order of the patches (used for plotting later)\n",
        "patchIDs = np.transpose(np.fliplr(np.array(patchIDs).reshape(3, 3))).ravel()\n",
        "    \n",
        "# Prepare info of selected EOPatches\n",
        "geometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list[patchIDs]]\n",
        "idxs_x = [info['index_x'] for info in info_list[patchIDs]]\n",
        "idxs_y = [info['index_y'] for info in info_list[patchIDs]]\n",
        "\n",
        "gdf = gpd.GeoDataFrame({'index_x': idxs_x, 'index_y': idxs_y}, \n",
        "                       crs={'init': CRS.ogc_string(country_crs)}, \n",
        "                       geometry=geometry)\n",
        "\n",
        "# save to shapefile\n",
        "shapefile_name = './selected_3x3_bboxes_slovenia_small.shp' if use_smaller_patches \\\n",
        "    else './selected_3x3_bboxes_slovenia_large.shp'\n",
        "gdf.to_file(shapefile_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOczsorQtSOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "poly = gdf['geometry'][0]\n",
        "x1, y1, x2, y2 = poly.bounds\n",
        "aspect_ratio = (y1 - y2) / (x1 - x2)\n",
        "\n",
        "# content of the geopandas dataframe\n",
        "gdf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVJOKWvftSYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fontdict = {'family': 'monospace', 'weight': 'normal', 'size': 11}\n",
        "\n",
        "# if bboxes have all same size, estimate offset\n",
        "xl, yl, xu, yu = gdf.geometry[0].bounds\n",
        "xoff, yoff = (xu - xl) / 3, (yu - yl) / 5\n",
        "\n",
        "# figure\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "gdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5)\n",
        "country.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5)\n",
        "ax.set_title('Selected 3x3  tiles from Slovenia (25 x 17 grid)');\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5GFUK3ItSfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentinelHubValidData:\n",
        "    \"\"\"\n",
        "    Combine Sen2Cor's classification map with `IS_DATA` to define a `VALID_DATA_SH` mask\n",
        "    The SentinelHub's cloud mask is asumed to be found in eopatch.mask['CLM']\n",
        "    \"\"\"\n",
        "    def __call__(self, eopatch):        \n",
        "        return np.logical_and(eopatch.mask['IS_DATA'].astype(np.bool), \n",
        "                              np.logical_not(eopatch.mask['CLM'].astype(np.bool)))\n",
        "    \n",
        "class CountValid(EOTask):   \n",
        "    \"\"\"\n",
        "    The task counts number of valid observations in time-series and stores the results in the timeless mask.\n",
        "    \"\"\"\n",
        "    def __init__(self, count_what, feature_name):\n",
        "        self.what = count_what\n",
        "        self.name = feature_name\n",
        "        \n",
        "    def execute(self, eopatch):\n",
        "        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.name, np.count_nonzero(eopatch.mask[self.what],axis=0))\n",
        "        \n",
        "        return eopatch\n",
        "\n",
        "\n",
        "class NormalizedDifferenceIndex(EOTask):   \n",
        "    \"\"\"\n",
        "    The tasks calculates user defined Normalised Difference Index (NDI) between two bands A and B as:\n",
        "    NDI = (A-B)/(A+B).\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, band_a, band_b):\n",
        "        self.feature_name = feature_name\n",
        "        self.band_a_fetaure_name = band_a.split('/')[0]\n",
        "        self.band_b_fetaure_name = band_b.split('/')[0]\n",
        "        self.band_a_fetaure_idx = int(band_a.split('/')[-1])\n",
        "        self.band_b_fetaure_idx = int(band_b.split('/')[-1])\n",
        "        \n",
        "    def execute(self, eopatch):\n",
        "        band_a = eopatch.data[self.band_a_fetaure_name][..., self.band_a_fetaure_idx]\n",
        "        band_b = eopatch.data[self.band_b_fetaure_name][..., self.band_b_fetaure_idx]\n",
        "        \n",
        "        ndi = (band_a - band_b) / (band_a  + band_b)\n",
        "        \n",
        "        eopatch.add_feature(FeatureType.DATA, self.feature_name, ndi[..., np.newaxis])\n",
        "        \n",
        "        return eopatch\n",
        "\n",
        "    \n",
        "class EuclideanNorm(EOTask):   \n",
        "    \"\"\"\n",
        "    The tasks calculates Euclidian Norm of all bands within an array:\n",
        "    norm = sqrt(sum_i Bi**2),\n",
        "    where Bi are the individual bands within user-specified feature array.\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, in_feature_name):\n",
        "        self.feature_name = feature_name\n",
        "        self.in_feature_name = in_feature_name\n",
        "    \n",
        "    def execute(self, eopatch):\n",
        "        arr = eopatch.data[self.in_feature_name]\n",
        "        norm = np.sqrt(np.sum(arr**2, axis=-1))\n",
        "        \n",
        "        eopatch.add_feature(FeatureType.DATA, self.feature_name, norm[..., np.newaxis])\n",
        "        return eopatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7GQqA33R33C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TASK FOR BAND DATA\n",
        "# add a request for B(B02), G(B03), R(B04), NIR (B08), SWIR1(B11), SWIR2(B12) \n",
        "# from default layer 'ALL_BANDS' at 10m resolution\n",
        "# Here we also do a simple filter of cloudy scenes. A detailed cloud cover \n",
        "# detection is performed in the next step\n",
        "custom_script = 'return [B02, B03, B04, B08, B11, B12];'\n",
        "add_data = S2L1CWCSInput(\n",
        "    layer='BANDS-S2-L1C', \n",
        "    feature=(FeatureType.DATA, 'BANDS'), # save under name 'BANDS'\n",
        "    custom_url_params={CustomUrlParam.EVALSCRIPT: custom_script}, # custom url for 6 specific bands\n",
        "    resx='10m', # resolution x\n",
        "    resy='10m', # resolution y\n",
        "    maxcc=0.8, # maximum allowed cloud cover of original ESA tiles\n",
        ")\n",
        "\n",
        "# TASK FOR CLOUD INFO\n",
        "# cloud detection is performed at 80m resolution \n",
        "# and the resulting cloud probability map and mask \n",
        "# are scaled to EOPatch's resolution\n",
        "cloud_classifier = get_s2_pixel_cloud_detector(average_over=2, dilation_size=1, all_bands=False)\n",
        "add_clm = AddCloudMaskTask(cloud_classifier, 'BANDS-S2CLOUDLESS', cm_size_y='80m', cm_size_x='80m', \n",
        "                           cmask_feature='CLM', # cloud mask name\n",
        "                           cprobs_feature='CLP' # cloud prob. map name\n",
        "                          )\n",
        "\n",
        "# TASKS FOR CALCULATING NEW FEATURES\n",
        "# NDVI: (B08 - B04)/(B08 + B04)\n",
        "# NDWI: (B03 - B08)/(B03 + B08)\n",
        "# NORM: sqrt(B02^2 + B03^2 + B04^2 + B08^2 + B11^2 + B12^2)\n",
        "ndvi = NormalizedDifferenceIndex('NDVI', 'BANDS/3', 'BANDS/2')\n",
        "ndwi = NormalizedDifferenceIndex('NDWI', 'BANDS/1', 'BANDS/3')\n",
        "norm = EuclideanNorm('NORM','BANDS')\n",
        "\n",
        "# TASK FOR VALID MASK\n",
        "# validate pixels using SentinelHub's cloud detection mask and region of acquisition \n",
        "add_sh_valmask = AddValidDataMaskTask(SentinelHubValidData(), \n",
        "                                      'IS_VALID' # name of output mask\n",
        "                                     )\n",
        "\n",
        "# TASK FOR COUNTING VALID PIXELS\n",
        "# count number of valid observations per pixel using valid data mask \n",
        "count_val_sh = CountValid('IS_VALID', # name of existing mask\n",
        "                          'VALID_COUNT' # name of output scalar\n",
        "                         )\n",
        "\n",
        "# TASK FOR SAVING TO OUTPUT (if needed)\n",
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "if not os.path.isdir(path_out):\n",
        "    os.makedirs(path_out)\n",
        "save = SaveToDisk(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAJaVJkDQH74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class LULC(Enum):\n",
        "    NO_DATA            = (0,  'No Data',            'white')\n",
        "    CULTIVATED_LAND    = (1,  'Cultivated Land',    'xkcd:lime')\n",
        "    FOREST             = (2,  'Forest',             'xkcd:darkgreen')\n",
        "    GRASSLAND          = (3,  'Grassland',          'orange')\n",
        "    SHRUBLAND          = (4,  'Shrubland',          'xkcd:tan')\n",
        "    WATER              = (5,  'Water',              'xkcd:azure')\n",
        "    WETLAND            = (6,  'Wetlands',           'xkcd:lightblue')\n",
        "    TUNDRA             = (7,  'Tundra',             'xkcd:lavender')\n",
        "    ARTIFICIAL_SURFACE = (8,  'Artificial Surface', 'crimson')\n",
        "    BARELAND           = (9,  'Bareland',           'xkcd:beige')\n",
        "    SNOW_AND_ICE       = (10, 'Snow and Ice',       'black')\n",
        "    \n",
        "    def __init__(self, val1, val2, val3):\n",
        "        self.id = val1\n",
        "        self.class_name = val2\n",
        "        self.color = val3\n",
        "        \n",
        "# example usecase\n",
        "# LULC.BARELAND.id   # return 9\n",
        "        \n",
        "# Reference colormap things\n",
        "lulc_cmap = mpl.colors.ListedColormap([entry.color for entry in LULC])\n",
        "lulc_norm = mpl.colors.BoundaryNorm(np.arange(-0.5, 11, 1), lulc_cmap.N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIJ3D-LSQIFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name_str = 'small' if use_smaller_patches else 'large'\n",
        "land_cover_path = os.path.join(DATA_FOLDER, 'land_cover_subset_{}'.format(name_str),\n",
        "                               'land_cover_subset_{}.shp'.format(name_str))\n",
        "\n",
        "land_cover_data = gpd.read_file(land_cover_path)\n",
        "\n",
        "rasterization_task = VectorToRaster(land_cover_data, (FeatureType.MASK_TIMELESS, 'LULC'),\n",
        "                                    values_column='lulcid', raster_shape=(FeatureType.MASK, 'IS_VALID'),\n",
        "                                    raster_dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEJ3JjWRQIZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the workflow\n",
        "workflow = LinearWorkflow(\n",
        "    add_data,\n",
        "    add_clm,\n",
        "    ndvi,\n",
        "    ndwi,\n",
        "    norm,\n",
        "    add_sh_valmask,\n",
        "    count_val_sh,\n",
        "    rasterization_task,\n",
        "    save\n",
        ")\n",
        "\n",
        "# Let's visualize it\n",
        "workflow.dependency_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBMymlIwQscq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Execute the workflow\n",
        "time_interval = ['2017-01-01', '2017-12-31'] # time interval for the SH request\n",
        "\n",
        "# define additional parameters of the workflow\n",
        "execution_args = []\n",
        "for idx, bbox in enumerate(bbox_list[patchIDs]):\n",
        "    execution_args.append({\n",
        "        add_data:{'bbox': bbox, 'time_interval': time_interval},\n",
        "        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n",
        "    })\n",
        "    \n",
        "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
        "executor.run(workers=5, multiprocess=False)\n",
        "\n",
        "executor.make_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elddNN3yQsks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EOPatch.load('./eopatches_small/eopatch_0/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXFzqk3eQsp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw the RGB image\n",
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "fig = plt.figure(figsize=(20, 20 * aspect_ratio))\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i in range(9):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(np.clip(eopatch.data['BANDS'][0][..., [2, 1, 0]] * 3.5, 0, 1))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7NkEM4_Qsy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    im = ax.imshow(eopatch.mask_timeless['LULC'].squeeze(), cmap=lulc_cmap, norm=lulc_norm)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "cb.set_ticks([entry.id for entry in LULC])\n",
        "cb.ax.set_xticklabels([entry.class_name for entry in LULC], rotation=45, fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LS9d0mHjrMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "vmin, vmax = None, None\n",
        "for i in range(9):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    data = eopatch.mask_timeless['VALID_COUNT'].squeeze()\n",
        "    vmin = np.min(data) if vmin is None else (np.min(data) if np.min(data) < vmin else vmin)\n",
        "    vmax = np.max(data) if vmax is None else (np.max(data) if np.max(data) > vmax else vmax)\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "    \n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    im = ax.imshow(eopatch.mask_timeless['VALID_COUNT'].squeeze(), vmin=vmin, vmax=vmax, cmap=plt.cm.inferno)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkpLfBiBjrPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "eID = 1\n",
        "eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, eID), lazy_loading=True)\n",
        "\n",
        "ndvi = eopatch.data['NDVI'] # ndvi data cube\n",
        "mask = eopatch.mask['IS_VALID'] # mask of valid pixels\n",
        "time = np.array(eopatch.timestamp) # x axis\n",
        "t, w, h, _ = ndvi.shape \n",
        "\n",
        "ndvi_clean = ndvi.copy()\n",
        "ndvi_clean[~mask] = np.nan # set values of invalid pixels to NaN's\n",
        "\n",
        "# Calculate means, remove NaN's from means\n",
        "ndvi_mean = np.nanmean(ndvi.reshape(t, w * h).squeeze(), axis=1) \n",
        "ndvi_mean_clean = np.nanmean(ndvi_clean.reshape(t, w * h).squeeze(), axis=1)\n",
        "time_clean = time[~np.isnan(ndvi_mean_clean)]\n",
        "ndvi_mean_clean = ndvi_mean_clean[~np.isnan(ndvi_mean_clean)]\n",
        "\n",
        "fig = plt.figure(figsize=(20,5))\n",
        "plt.plot(time_clean, ndvi_mean_clean, 's-', label = 'Mean NDVI with cloud cleaning')\n",
        "plt.plot(time, ndvi_mean, 'o-', label='Mean NDVI without cloud cleaning')\n",
        "plt.xlabel('Time', fontsize=15)\n",
        "plt.ylabel('Mean NDVI over patch', fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "\n",
        "plt.legend(loc=2, prop={'size': 15});"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMohHcHVjrKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "    \n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    ndvi = eopatch.data['NDVI']\n",
        "    mask = eopatch.mask['IS_VALID']\n",
        "    ndvi[~mask] = np.nan\n",
        "    ndvi_mean = np.nanmean(ndvi, axis=0).squeeze()\n",
        "    im = ax.imshow(ndvi_mean, vmin=0, vmax=0.8, cmap=plt.get_cmap('YlGn'))\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qhUgAcgj486",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "    \n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n",
        "    clp = eopatch.data['CLP']\n",
        "    mask = eopatch.mask['IS_VALID']\n",
        "    clp[~mask] = np.nan\n",
        "    clp_mean = np.nanmean(clp, axis=0).squeeze()\n",
        "    im = ax.imshow(clp_mean, vmin=0.0, vmax=0.3, cmap=plt.cm.inferno)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgziXgiAj5Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatenateData(EOTask):\n",
        "    \"\"\" Task to concatenate data arrays along the last dimension\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, feature_names_to_concatenate):\n",
        "        self.feature_name = feature_name\n",
        "        self.feature_names_to_concatenate = feature_names_to_concatenate\n",
        "\n",
        "    def execute(self, eopatch):\n",
        "        arrays = [eopatch.data[name] for name in self.feature_names_to_concatenate]\n",
        "\n",
        "        eopatch.add_feature(FeatureType.DATA, self.feature_name, np.concatenate(arrays, axis=-1))\n",
        "\n",
        "        return eopatch\n",
        "    \n",
        "    \n",
        "class ValidDataFractionPredicate:\n",
        "    \"\"\" Predicate that defines if a frame from EOPatch's time-series is valid or not. Frame is valid, if the \n",
        "    valid data fraction is above the specified threshold.\n",
        "    \"\"\"\n",
        "    def __init__(self, threshold):\n",
        "        self.threshold = threshold\n",
        "        \n",
        "    def __call__(self, array):\n",
        "        coverage = np.sum(array.astype(np.uint8)) / np.prod(array.shape)\n",
        "        return coverage > self.threshold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moOukGM0j5EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TASK TO LOAD EXISTING EOPATCHES\n",
        "load = LoadFromDisk(path_out)\n",
        "\n",
        "# TASK FOR CONCATENATION\n",
        "concatenate = ConcatenateData('FEATURES', ['BANDS', 'NDVI', 'NDWI', 'NORM'])\n",
        "\n",
        "# TASK FOR FILTERING OUT TOO CLOUDY SCENES\n",
        "# keep frames with > 80 % valid coverage\n",
        "valid_data_predicate = ValidDataFractionPredicate(0.8)\n",
        "filter_task = SimpleFilterTask((FeatureType.MASK, 'IS_VALID'), valid_data_predicate)\n",
        "\n",
        "# TASK FOR LINEAR INTERPOLATION\n",
        "# linear interpolation of full time-series and date resampling\n",
        "resampled_range = ('2017-01-01', '2017-12-31', 16)\n",
        "linear_interp = LinearInterpolation(\n",
        "    'FEATURES', # name of field to interpolate\n",
        "    mask_feature=(FeatureType.MASK, 'IS_VALID'), # mask to be used in interpolation\n",
        "    copy_features=[(FeatureType.MASK_TIMELESS, 'LULC')], # features to keep\n",
        "    resample_range=resampled_range, # set the resampling range\n",
        "    bounds_error=False # extrapolate with NaN's\n",
        ")\n",
        "\n",
        "# TASK FOR EROSION\n",
        "# erode each class of the reference map\n",
        "erosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'LULC','LULC_ERODED'), disk_radius=1)\n",
        "\n",
        "# TASK FOR SPATIAL SAMPLING\n",
        "# Uniformly sample about pixels from patches\n",
        "n_samples = int(4e4) if use_smaller_patches else int(1e5) # no. of pixels to sample\n",
        "ref_labels = list(range(11)) # reference labels to take into account when sampling\n",
        "spatial_sampling = PointSamplingTask(\n",
        "    n_samples=n_samples, \n",
        "    ref_mask_feature='LULC_ERODED', \n",
        "    ref_labels=ref_labels, \n",
        "    sample_features=[  # tag fields to sample\n",
        "        (FeatureType.DATA, 'FEATURES'),\n",
        "        (FeatureType.MASK_TIMELESS, 'LULC_ERODED')\n",
        "    ])\n",
        "\n",
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "if not os.path.isdir(path_out_sampled):\n",
        "    os.makedirs(path_out_sampled)\n",
        "save = SaveToDisk(path_out_sampled, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2WFTX1yj4_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the workflow\n",
        "workflow = LinearWorkflow(\n",
        "    load,\n",
        "    concatenate,\n",
        "    filter_task,\n",
        "    linear_interp,\n",
        "    erosion,\n",
        "    spatial_sampling,\n",
        "    save\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA5i3gYzkHB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%%time\n",
        "   \n",
        "execution_args = []\n",
        "for idx in range(len(patchIDs)):\n",
        "    execution_args.append({\n",
        "        load: {'eopatch_folder': 'eopatch_{}'.format(idx)},\n",
        "        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n",
        "    })\n",
        "    \n",
        "executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
        "executor.run(workers=5, multiprocess=True)\n",
        "\n",
        "executor.make_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C7DWleHkHEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load sampled eopatches\n",
        "eopatches = []\n",
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "\n",
        "for i in range(9):\n",
        "    eopatches.append(EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True))    \n",
        "\n",
        "eopatches = np.array(eopatches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S02WeIyIkHHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Definition of the train and test patch IDs\n",
        "train_ID = [0,2,3,4,5,6,7,8] if use_smaller_patches else [0,1,3,4,5,6,7,8]\n",
        "test_ID = [1] if use_smaller_patches else [2]\n",
        "\n",
        "# Set the features and the labels for train and test sets\n",
        "features_train = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[train_ID]])\n",
        "labels_train = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches[train_ID]])\n",
        "features_test = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[test_ID]])\n",
        "labels_test = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches[test_ID]])\n",
        "\n",
        "# get shape\n",
        "p1, t, w, h, f = features_train.shape\n",
        "p2, t, w, h, f = features_test.shape\n",
        "p = p1 + p2\n",
        "\n",
        "# reshape to n x m\n",
        "features_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\n",
        "labels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\n",
        "features_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\n",
        "labels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n",
        "\n",
        "# remove points with no reference from training (so we dont train to recognize \"no data\")\n",
        "mask_train = labels_train == 0\n",
        "features_train = features_train[~mask_train]\n",
        "labels_train = labels_train[~mask_train]\n",
        "\n",
        "# remove points with no reference from test (so we dont validate on \"no data\", which doesn't make sense)\n",
        "mask_test = labels_test == 0\n",
        "features_test = features_test[~mask_test]\n",
        "labels_test = labels_test[~mask_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QisuUczPloIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Set up training classes\n",
        "labels_unique = np.unique(labels_train)\n",
        "\n",
        "# Set up the model\n",
        "model = lgb.LGBMClassifier(\n",
        "    objective='multiclass', \n",
        "    num_class=len(labels_unique), \n",
        "    metric='multi_logloss'\n",
        ")\n",
        "\n",
        "# train the model\n",
        "model.fit(features_train, labels_train)\n",
        "\n",
        "# uncomment to save the model\n",
        "model_base_name = 'model_SI_LULC_smaller' if use_smaller_patches else 'model_SI_LULC_larger'\n",
        "joblib.dump(model, './{}.pkl'.format(model_base_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaIQL5HeloF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uncomment to load the model and replace with your file, usually just correct the date\n",
        "model_path = './model_SI_LULC_smaller.pkl' if use_smaller_patches else './model_SI_LULC_larger.pkl'\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# predict the test labels\n",
        "plabels_test = model.predict(features_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdZRajvmloDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_test, plabels_test)))\n",
        "print('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_test, plabels_test, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ospmao3MmvXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = np.unique(labels_test)\n",
        "class_names = [entry.class_name for entry in LULC]\n",
        "\n",
        "f1_scores = metrics.f1_score(labels_test, plabels_test, labels=class_labels, average=None)\n",
        "recall = metrics.recall_score(labels_test, plabels_test, labels=class_labels, average=None)\n",
        "precision = metrics.precision_score(labels_test, plabels_test, labels=class_labels, average=None) \n",
        "\n",
        "print('             Class              =  F1  | Recall | Precision')\n",
        "print('         --------------------------------------------------')\n",
        "for idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n",
        "    print('         * {0:20s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}'.format(lulctype, \n",
        "                                                                         f1_scores[idx] * 100, \n",
        "                                                                         recall[idx] * 100, \n",
        "                                                                         precision[idx] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91qu8CDDmvVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the plotting function\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues, ylabel='True label', xlabel='Predicted label', filename=None):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    np.set_printoptions(precision=2, suppress=True)\n",
        "    \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + np.finfo(np.float).eps)\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n",
        "    plt.title(title, fontsize=20)\n",
        "    # plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, fontsize=20)\n",
        "    plt.yticks(tick_marks, classes, fontsize=20)\n",
        "    \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "                 fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel(ylabel, fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4hQ-icKmvTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "conf_matrix_gbm = metrics.confusion_matrix(labels_test, plabels_test)\n",
        "plot_confusion_matrix(conf_matrix_gbm, \n",
        "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n",
        "                      normalize=True, \n",
        "                      ylabel='Truth (LAND COVER)', \n",
        "                      xlabel='Predicted (GBM)',\n",
        "                      title='Confusion matrix');\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "conf_matrix_gbm = metrics.confusion_matrix(plabels_test, labels_test)\n",
        "plot_confusion_matrix(conf_matrix_gbm, \n",
        "                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n",
        "                      normalize=True, \n",
        "                      xlabel='Truth (LAND COVER)', \n",
        "                      ylabel='Predicted (GBM)',\n",
        "                      title='Transposed Confusion matrix');\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5JOLgWmvPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20, 5))\n",
        "\n",
        "label_ids, label_counts = np.unique(labels_train, return_counts=True)\n",
        "\n",
        "plt.bar(range(len(label_ids)), label_counts)\n",
        "plt.xticks(range(len(label_ids)), [class_names[i] for i in label_ids], rotation=45, fontsize=20);\n",
        "plt.yticks(fontsize=20);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqJRhcvmnGb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = np.unique(np.hstack([labels_test, labels_train]))\n",
        "\n",
        "scores_test = model.predict_proba(features_test)\n",
        "labels_binarized = preprocessing.label_binarize(labels_test, classes=class_labels)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for idx,lbl in enumerate(class_labels):\n",
        "    fpr[idx], tpr[idx], _ = metrics.roc_curve(labels_binarized[:, idx], scores_test[:, idx])\n",
        "    roc_auc[idx] = metrics.auc(fpr[idx], tpr[idx])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afwSjvKEnGYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "for idx,lbl in enumerate(class_labels):\n",
        "    if np.isnan(roc_auc[idx]):\n",
        "        continue\n",
        "    plt.plot(fpr[idx], tpr[idx], color=lulc_cmap.colors[lbl],\n",
        "         lw=2, label=class_names[lbl] + ' (%0.5f)' % roc_auc[idx])\n",
        "    \n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 0.99])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=20)\n",
        "plt.ylabel('True Positive Rate', fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.title('ROC Curve', fontsize=20)\n",
        "plt.legend(loc=\"center right\", prop={'size': 15})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuPsjtyynGVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# names of features\n",
        "fnames = ['B2','B3','B4','B8','B11','B12','NDVI','NDWI','NORM']\n",
        "\n",
        "# get feature importances and reshape them to dates and features\n",
        "z = model.feature_importances_.reshape((t, f))\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "ax = plt.gca()\n",
        "\n",
        "# plot the importances\n",
        "im = ax.imshow(z, aspect=0.25)\n",
        "plt.xticks(range(len(fnames)), fnames, rotation=45, fontsize=20)\n",
        "plt.yticks(range(t), ['T{}'.format(i) for i in range(t)], fontsize=20)\n",
        "plt.xlabel('Bands and band related features', fontsize=20)\n",
        "plt.ylabel('Time frames', fontsize=20)\n",
        "ax.xaxis.tick_top()\n",
        "ax.xaxis.set_label_position('top') \n",
        "\n",
        "# cax = fig.add_axes([0.82, 0.125, 0.04, 0.755]) \n",
        "# plt.colorbar(im, cax=cax)\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=[ax], orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR8cZR0pnGRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Draw the RGB image\n",
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "fig = plt.figure(figsize=(20, 20 * aspect_ratio))\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i in range(9):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(np.clip(eopatch.data['FEATURES'][1][..., [2, 1, 0]] * 2.5, 0, 1))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "    del eopatch\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJnqt4FpnVZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b2_t1 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                    1, 3)[..., 1, 0].reshape(p * h * w)\n",
        "b2_t19 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                     1, 3)[..., 19, 0].reshape(p * h * w)\n",
        "ndvi_t1 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                      1, 3)[..., 1, 6].reshape(p * h * w)\n",
        "ndvi_t19 = np.moveaxis(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches]),\n",
        "                       1, 3)[..., 19, 6].reshape(p * h * w)\n",
        "labels = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches]).reshape(p * h * w * 1)\n",
        "\n",
        "# remove nans\n",
        "mask = np.any([np.isnan(b2_t1), np.isnan(b2_t19), np.isnan(ndvi_t1), np.isnan(ndvi_t19), labels==0], axis=0)\n",
        "b2_t1, b2_t19, ndvi_t1, ndvi_t19, labels = [array[~mask] for array in [b2_t1, b2_t19, ndvi_t1, ndvi_t19, labels]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntkHWSprnVXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "plot_labels = np.unique(labels)\n",
        "plot_colors = lulc_cmap.colors\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.hist([b2_t1[labels == i] for i in np.unique(labels)], 100, (0.1, 0.7),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('B2', fontsize=20)\n",
        "plt.title('Optimal time', fontsize=20)\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.hist([b2_t19[labels == i] for i in np.unique(labels)],100,(0.1, 0.7),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('B2', fontsize=20);\n",
        "plt.title('Non-optimal time', fontsize=20)\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.hist([ndvi_t1[labels == i] for i in plot_labels],100,(-0.4, 0.8),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels],\n",
        "         label=[class_names[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('NDVI', fontsize=20)\n",
        "plt.legend(loc=1, prop={'size': 15})\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.hist([ndvi_t19[labels == i] for i in np.unique(labels)],100,(-0.4, 0.8),histtype='step', \n",
        "         color=[plot_colors[i] for i in plot_labels]);\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.xlabel('NDVI', fontsize=20);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHNVBY_cnVTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictPatch(EOTask):\n",
        "    \"\"\"\n",
        "    Task to make model predictions on a patch. Provide the model and the feature, \n",
        "    and the output names of labels and scores (optional)\n",
        "    \"\"\"\n",
        "    def __init__(self, model, features_feature, predicted_labels_name, predicted_scores_name=None):\n",
        "        self.model = model\n",
        "        self.features_feature = features_feature\n",
        "        self.predicted_labels_name = predicted_labels_name\n",
        "        self.predicted_scores_name = predicted_scores_name\n",
        "        \n",
        "    def execute(self, eopatch):\n",
        "        ftrs = eopatch[self.features_feature[0]][self.features_feature[1]]\n",
        "        \n",
        "        t, w, h, f = ftrs.shape\n",
        "        ftrs = np.moveaxis(ftrs, 0, 2).reshape(w * h, t * f)\n",
        "        \n",
        "        plabels = self.model.predict(ftrs)\n",
        "        plabels = plabels.reshape(w, h)\n",
        "        plabels = plabels[..., np.newaxis]\n",
        "        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.predicted_labels_name, plabels)\n",
        "        \n",
        "        if self.predicted_scores_name:\n",
        "            pscores = self.model.predict_proba(ftrs)\n",
        "            _, d = pscores.shape\n",
        "            pscores = pscores.reshape(w, h, d)\n",
        "            eopatch.add_feature(FeatureType.DATA_TIMELESS, self.predicted_scores_name, pscores)\n",
        "        \n",
        "        return eopatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugG2C261ntDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK TO LOAD EXISTING EOPATCHES\n",
        "load = LoadFromDisk(path_out_sampled)\n",
        "\n",
        "# TASK FOR PREDICTION\n",
        "predict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', 'SCR_GBM')\n",
        "\n",
        "# TASK FOR SAVING\n",
        "save = SaveToDisk(str(path_out_sampled), overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
        "\n",
        "# TASK TO EXPORT TIFF\n",
        "export_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LBL_GBM'))\n",
        "tiff_location = './predicted_tiff'\n",
        "if not os.path.isdir(tiff_location):\n",
        "    os.makedirs(tiff_location)\n",
        "\n",
        "workflow = LinearWorkflow(\n",
        "    load,\n",
        "    predict,\n",
        "    export_tiff,\n",
        "    save\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1NOU3uMntAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of execution arguments for each patch\n",
        "execution_args = []\n",
        "for i in range(len(patchIDs)):\n",
        "    execution_args.append(\n",
        "        {\n",
        "            load: {'eopatch_folder': 'eopatch_{}'.format(i)},\n",
        "            export_tiff: {'filename': '{}/prediction_eopatch_{}.tiff'.format(tiff_location, i)},\n",
        "            save: {'eopatch_folder': 'eopatch_{}'.format(i)}\n",
        "        }\n",
        "    )\n",
        "\n",
        "# run the executor on 2 cores\n",
        "executor = EOExecutor(workflow, execution_args)\n",
        "\n",
        "# uncomment below save the logs in the current directory and produce a report!\n",
        "#executor = EOExecutor(workflow, execution_args, save_logs=True)\n",
        "\n",
        "executor.run(workers=2, multiprocess=False)\n",
        "executor.make_report()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJdIxr4zns8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# merge with gdal_merge.py (with compression) using bash command magic\n",
        "!gdal_merge.py -o predicted_tiff/merged_prediction.tiff -co compress=LZW predicted_tiff/prediction_eopatch_*\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09E6hs0uoSdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n",
        "\n",
        "pbar = tqdm(total=9)\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True)\n",
        "    im = ax.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze(), cmap=lulc_cmap, norm=lulc_norm)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_aspect(\"auto\")\n",
        "    pbar.update(1)\n",
        "\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "cb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\n",
        "cb.ax.tick_params(labelsize=20) \n",
        "cb.set_ticks([entry.id for entry in LULC])\n",
        "cb.ax.set_xticklabels([entry.class_name for entry in LULC], rotation=45, fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC_mw9hUoSbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Draw the Reference map\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "idx = np.random.choice(range(9))\n",
        "inspect_size = 100\n",
        "\n",
        "eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, idx), lazy_loading=True)\n",
        "\n",
        "w, h = eopatch.mask_timeless['LULC'].squeeze().shape\n",
        "\n",
        "w_min = np.random.choice(range(w - inspect_size))\n",
        "h_min = np.random.choice(range(h - inspect_size))\n",
        "\n",
        "ax = plt.subplot(2, 2, 1)\n",
        "plt.imshow(eopatch.mask_timeless['LULC'].squeeze()[w_min: w_min + inspect_size, h_min : h_min + inspect_size],\n",
        "           cmap=lulc_cmap, norm=lulc_norm)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('Ground Truth', fontsize=20)\n",
        "\n",
        "ax = plt.subplot(2, 2, 2)\n",
        "plt.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze()[w_min: w_min + inspect_size, h_min: h_min + inspect_size],\n",
        "           cmap=lulc_cmap, norm=lulc_norm)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('Prediction', fontsize=20)\n",
        "\n",
        "ax = plt.subplot(2, 2, 3)\n",
        "mask = eopatch.mask_timeless['LBL_GBM'].squeeze() != eopatch.mask_timeless['LULC'].squeeze()\n",
        "plt.imshow(mask[w_min: w_min + inspect_size, h_min: h_min + inspect_size], cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([]);\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('Difference', fontsize=20)\n",
        "\n",
        "ax = plt.subplot(2, 2, 4)\n",
        "image = np.clip(eopatch.data['FEATURES'][8][..., [2, 1, 0]] * 3.5, 0, 1)\n",
        "plt.imshow(image[w_min: w_min + inspect_size, h_min: h_min + inspect_size])\n",
        "plt.xticks([])\n",
        "plt.yticks([]);\n",
        "ax.set_aspect(\"auto\")\n",
        "plt.title('True Color', fontsize=20)\n",
        "\n",
        "fig.subplots_adjust(wspace=0.1, hspace=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_MHdpOuoSYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrTZkof5oSTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}